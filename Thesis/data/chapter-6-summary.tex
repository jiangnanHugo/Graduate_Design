\chapter*{结论和展望}
Mikolov曾提出使用基于二叉树的层级softmax模型来加速的训练方案，加速比能达到理论的最大速度，但是当时提出的背景是基于CPU构建的，如今越来越多的算法随着应用领域的推广，需要在并行度更高的GPU上进行计算，因此基于GPU进行建模的tHSM尚未被研究提及，需要在本文中研讨。
\section*{工作总结}
当我们使用多层分类模型的时候，我们就需要将单词按照模型的架构进行划分。其中对于cHSM模型，我们有以下策略可以使用：a） 基于词频划分类别； b） 基于Bigram 的布朗聚类(Brown clustering) 进行划分；c）按照word-embedding 的词向量信息进行聚类。另外，我们还需要注意的是，各个类别可以包含不同的数量的单词，也可以包含数量相同的单词。对于后者，我们考虑的划分模型就是基于交换算法（Exchange Algorithm）, 以此来保证获得近似的最优解。


目前存在的问题主要是两点：模型仍然计算很复杂需要使用更底层语言来加速计算，和目前采用的聚类算法比较费时间。

由于我们选择的建模平台是python平台，好处是可以使用许多现成的已有的框架。并且python语法简单，矩阵计算库numpy和scipy更成熟，便于调试。另一方面，我们采用的建模语言是theano框架，它的底层计算都是调用BLAS计算库，或者直接调用基于GPU的CUDA的CuBLAS计算库。虽然这样做便于在前期模型建立阶段能方便尝试各种设计方案，但是他的计算瓶颈在python解释器对代码的缓慢执行，所以如果能将部分模型组件使用CUDA语言重写。那样的话，我们的模型能接受一定的组合排列的可能性，同时计算速度能得到极大提升。这也是许多目前流行框架发展的方向，有些框架更超前。例如MXNET直接使用C++语言建立深度模型，他的计算效率也是目前已知的框架中最快的。因此，考虑到目前的thenao计算瓶颈，我们想将RNN的框架使用CUDA语言重构，基于CuDNN库开发的样板，帮助我们在他基础上改进。

另一方面，目前采用的聚类算法计算非常费时，尤其是当我们希望进行多层次聚类的时候，我们需要花费数周时间来获得结果。这样的缓慢的计算效果是无法接受的，经过针对代码的调试，我们发现计算瓶颈在算法初始化的时候，计算两两单词之间的距离，它花费了90\%的计算时间。如果能存在有效的初始化算法，而不是挑选尽可能高精度的聚类模型，那么实验进度和试验结果就可以针对多组参数调试。
\section*{工作展望}
\begin{enumerate}
\item 大规模实验数据分析验证算法；
\item 优化模型速度，用底层语言封装模型，以达到最好的效果；
\item 实验和评价不同聚类算法的效果；
\item 讨论和研究不同语言模型优化方案的优缺点，以及使用场景。
\end{enumerate}
\begin{enumerate}
\item 大规模实验数据分析验证算法：目前已经找到三个标准文本数据集，需要重写数据处理算法，这样保证模型能正常运算和收敛；
\item 优化模型速度，用底层语言封装模型，以达到最好的效果：学习CUDA语言，并着手构建基于深度学习的模型框架；
\item 实验和评价不同聚类算法的效果：调研可用的层次聚类算法并进行测试和实验检验；
\item 讨论和研究不同语言模型优化方案的优缺点，以及使用场景：提出不同的实验评价指标，观察不同模型的结果，并分析其背后的原因。
\end{enumerate} 