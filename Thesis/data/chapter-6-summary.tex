\summary
大词表问题是语言模型应用中最重要的挑战之一，为了解决这个问题，文献中提出了各种方法可大致分为三个类别：词汇截断算法，基于抽样的近似算法和词表层次分解。第三种方法将目标词汇的扁平化架构改变为具有两种可能的分层结构：类和树层次分解。构建在两步softmax分类方法和树模型上的类方法将其扩展到$\mathcal {O(| H | \log | V |)} $步骤的二进制分类。Mikolov~曾提出使用基于二叉树的层级概率模型来加速的训练方案，加速比能达到理论的最大速度，但是当时提出的背景是基于CPU构建的，如今越来越多的算法随着应用领域的推广，需要在并行度更高的~GPGPU~设备上进行计算，因此基于GPGPU进行建模的层次概率模型尚未被研究提及，需要在本文中研讨。
\section*{工作总结}
多层分类模型需要将单词按照模型的架构进行划分。其中以下策略适用于~cHSM~模型：基于词频划分类别、 基于布朗聚类进行划分、按照词向量信息进行聚类等方法，另外词表是否能均划分与具体层次聚类算法相关。


\noindent 1. 本论文中，针对两种层次概率模型，首先定义了对应编码方式，同时给出了模型所涉及的参数的详细含义。接下来，我们逐步推导模型的单个节点的概率公式，单个词的概率公式和模型的代价函数。另一方面，我们将提出的~p-tHSM~算法和传统的线性~tHSM~算法进行的比较。通过比较两者计算的差异性证明我们提出的算法更适合在GPGPU等高并行设备上运算。本文还进一步讨论了模型在测试的时候所需的推理算法，因为基于层次结构的概率计算方案和传统的softmax计算方案不同，不能直接输出单个词的概率或者计算最佳的候选单词，所以我们分别针对这两个任务提出推理算法。最后，由于单词在二叉树上的分布需要初始化，我们讨论了现存的各种聚类算法效果。

\noindent 2. 在实际实验中，我们提出的层次概率模型的计算速度比传统模型相对较快。配合不同的层次聚类算法，层次概率模型也能获得较好的预测准确度和稳定性。相比于采样算法，模型能在测试的阶段也获得同样的计算加速效果。相比于传统的softmax函数，尽管层次概率模型的精确度稍低，但是模型的计算速度极大提升。

\section*{工作展望}
本文提出的层次概率模型在语言模型的各项评测上取得了有效的结果，验证了本方法的合理性。但是该方法还存在进一步提升的空间：

\noindent 1. 大规模实验数据分析验证算法：由于在现有实验环境条件下，在大数据集上的实验验证过程收敛很慢，所以目前的实验主要还是在小规模数据集上进行了初步验证，下一步将进一步在大数据集上进行验证并比较算法的差异，进一步验证算法的广泛适用性。

\noindent 2. 由于我们选择的建模平台是python语言，优点是可以使用许多现成的已有的框架，并且python语法简单，矩阵计算库numpy和scipy更成熟，便于调试。另一方面，我们采用的建模语言是theano框架，它的底层计算都是调用BLAS计算库，或者直接调用基于CUDA的CuBLAS计算库实现的。虽然这样做便于在前期模型建立阶段能方便尝试各种设计方案，但是计算瓶颈在于python的解释器执行代码缓慢，所以如果能将部分模型组件使用CUDA语言重写，允许本论文提出的模型调试各种组合的神经网络结构，使得整体计算速度能得到更大提升，这也是许多目前流行框架发展的方向，例如Mxnet\footnote{http://mxnet.incubator.apache.org/}和caffe2\footnote{https://caffe2.ai/}直接使用~C++~语言建立深度模型，其计算效率也是目前已知的框架中最快的。因此考虑到目前的Thenao计算瓶颈，下一步将重点研究如何将RNN的框架使用CUDA语言重构，并基于CuDNN 库开发的样例代码进行改进。


\noindent 3. 本实验中采用了不同聚类算法，并分析了各个聚类算法的优劣。目前采用的聚类算法计算非常费时，尤其是当我们希望进行多层次聚类的时候，需要花费数周时间来获得结果。这样的缓慢的计算效果是无法接受的，经过针对代码的调试发现计算瓶颈在算法初始化的过程中，它花费了90\%的计算时间在计算两两单词之间的距离。如果能存在有效的初始化算法，而不是挑选尽可能高精度的聚类模型，那么实验进度和试验结果就可以针对多组参数调试。我们也可以考虑，单词分布也是随机初始化，在模型训练的时候动态计算单词交换策略，随着模型的收敛，单词的划分结构也逐渐收敛，这样一来就不需要在使用额外的计算库，给模型添加各种初始化词表分布。除此之外，还需要探讨除了语言模型的应用场景，我们还可以应用到大规模标签分类，或者更接近的机器翻译领域中。
